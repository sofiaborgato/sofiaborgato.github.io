---
title: "Incremental learning"
excerpt: "The main goal of this project is to implement a neural network capable of learning different tasks without forgetting the ones it has learned before."
collection: portfolio
---

The main goal of this project is to implement a neural network capable of learning different tasks without forgetting the ones it has learned before.
This is a very important goal for neural network, the one that most approaches neural networks to artificial intelligence. 
It is a relatively new problem, so in literature there are not so many papers. 
We can formalize the purpose of this work in the following way: given a CNN with certain shared parameters $\theta_s$, add task specific parameters $\theta_n$ for a new task that works well both on old and new tasks.
There are some constrains that defines that the network is incremental learning new tasks:
<ul>
    <li> The model has to adapt gradually i.e. is constructed based on without complete retraining.
    <li> Preservation of previously acquired knowledge and without the effect of catastrophic forgetting.
    <li> Data from previous tasks are not available when new tasks are processed.
</ul>
I reproduce two bases approaches:
<ul>
    <li> Learning without forgetting, 
    <li> ICaRL
</ul>

  
The code and the related report are available <a href="https://github.com/sofiaborgato/Incremental_Class_Learning" >here</a>
